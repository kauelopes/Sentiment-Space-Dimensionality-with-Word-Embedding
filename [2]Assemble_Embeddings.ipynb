{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[0]\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "import json #https://stackoverflow.com/questions/7100125/storing-python-dictionaries\n",
    "import pickle #https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "import os\n",
    "#[1]\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.spatial import procrustes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#[2]\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemble_embeddings_soma = get_emb_soma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemble_embeddings_concat = get_emb_concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemble_embeddings_media = get_emb_media()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_soma():\n",
    "    embeddings = get_clean_embeddings()\n",
    "    sentiments = get_sentiments()\n",
    "    assemble_embeddings_soma = np.zeros_like(embeddings[0])\n",
    "    for i in embeddings:\n",
    "        for c in range(75):\n",
    "            assemble_embeddings_soma[c] = assemble_embeddings_soma[c] + i[c]\n",
    "    return assemble_embeddings_soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_concat():\n",
    "    embeddings = get_clean_embeddings()\n",
    "    sentiments = get_sentiments()\n",
    "    assemble_embeddings_concat = []\n",
    "\n",
    "    for c in range(75):\n",
    "        tmp = np.array([])\n",
    "        for i in embeddings:\n",
    "            tmp = np.concatenate((tmp,i[c]))\n",
    "        assemble_embeddings_concat += [tmp]\n",
    "    return assemble_embeddings_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_media():\n",
    "    #média dos vetores e retirando outliers\n",
    "    embeddings = get_clean_embeddings()\n",
    "    sentiments = get_sentiments()\n",
    "    assemble_embeddings_media = np.zeros_like(embeddings[0])\n",
    "    vec = []\n",
    "    dist = []\n",
    "    for c in range(75):\n",
    "        tmp = np.array([])\n",
    "        vec = []\n",
    "        for i in embeddings:\n",
    "            vec += [i[c]]\n",
    "\n",
    "        centroid = np.zeros_like(vec[0])\n",
    "        for i in vec:\n",
    "            centroid = centroid + i\n",
    "        centroid = centroid/len(vec)\n",
    "\n",
    "        dist = []\n",
    "        for i in vec:\n",
    "            dist += [np.linalg.norm(i-centroid)]\n",
    "\n",
    "        limitante_distancia_para_corte = np.max(dist)\n",
    "\n",
    "        counter = 0\n",
    "        for n,i in enumerate(embeddings):\n",
    "            if dist[n]!=limitante_distancia_para_corte:\n",
    "                assemble_embeddings_media[c] += i[c] \n",
    "                counter+=1\n",
    "\n",
    "        assemble_embeddings_media[c] = assemble_embeddings_media[c]/counter\n",
    "    return assemble_embeddings_media\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_embeddings():\n",
    "#Seleciona somente os vetores principais das nossas embeddings\n",
    "    sentiments = get_sentiments()\n",
    "    raw_embeddings = []\n",
    "    dimensions_size = []\n",
    "    for i in range(5):\n",
    "        tmp = get_vectors_embedding(i)\n",
    "        raw_embeddings += [tmp]\n",
    "        dimensions_size+=[len(get_sentiment_vector(tmp,sentiments[0]))]\n",
    "#Faz o corte para o menor tamanho de dimensão\n",
    "    n_dimensions = np.min(dimensions_size)\n",
    "    # n_dimensions = 10\n",
    "    mds = MDS(n_components=n_dimensions)\n",
    "#Trata embeddings, filtrando somente os sentimentos principais e colocando no numero minimo de dimensoes\n",
    "    embeddings = []\n",
    "    for i in range(5):\n",
    "        tmp_embedding = []\n",
    "        for s in sentiments:\n",
    "            tmp_embedding += [get_sentiment_vector(raw_embeddings[i],s)]\n",
    "        transformed_embedding = mds.fit_transform(tmp_embedding)\n",
    "        embeddings += [transformed_embedding]\n",
    "    # Calcula erro entre nossos modelos\n",
    "    for a in range(len(embeddings)):\n",
    "        for b in range(len(embeddings)):\n",
    "            embeddings[a],embeddings[b],r = procrustes(embeddings[a],embeddings[b])\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_anotado(emb):\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    ax.scatter(emb[:,0], emb[:,1])\n",
    "    n = get_sentiments()\n",
    "    \n",
    "    for i, txt in enumerate(n):\n",
    "        ax.annotate(\" \"+txt, (emb[:,0][i], emb[:,1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_anotado2(emb):\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    for e in emb:\n",
    "        ax.scatter(e[:,0], e[:,1])\n",
    "        n = get_sentiments()\n",
    "\n",
    "        for i, txt in enumerate(n):\n",
    "            ax.annotate(txt, (e[:,0][i], e[:,1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_2d(embs):\n",
    "    res = []\n",
    "    mds_2 = MDS(n_components=2)\n",
    "    for e in embs:\n",
    "        res += [mds_2.fit_transform(e)]\n",
    "    for p in res:\n",
    "        plt.scatter(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_vector(embedding, sentiment):\n",
    "    return embedding[sentiment][\"vectors\"][sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_embedding(n):\n",
    "    files = os.listdir(\"models\")\n",
    "    model_file_name = []\n",
    "    for file in files:\n",
    "        model_file_name += [file]\n",
    "    escolhidos = [model_file_name[11],model_file_name[14],model_file_name[5],model_file_name[7],model_file_name[3]]\n",
    "    with open(\"models/\"+escolhidos[n], 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiments():\n",
    "    sentiments = np.load(\"./sentiments_list.npy\")\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_soma():\n",
    "    embeddings = get_clean_embeddings()\n",
    "    sentiments = get_sentiments()\n",
    "    assemble_embeddings_soma = np.zeros_like(embeddings[0])\n",
    "    for i in embeddings:\n",
    "        for c in range(75):\n",
    "            assemble_embeddings_soma[c] = assemble_embeddings_soma[c] + i[c]\n",
    "    return assemble_embeddings_soma\n",
    "\n",
    "def get_emb_concat():\n",
    "    embeddings = get_clean_embeddings()\n",
    "    sentiments = get_sentiments()\n",
    "    assemble_embeddings_concat = []\n",
    "\n",
    "    for c in range(75):\n",
    "        tmp = np.array([])\n",
    "        for i in embeddings:\n",
    "            tmp = np.concatenate((tmp,i[c]))\n",
    "        assemble_embeddings_concat += [tmp]\n",
    "    return assemble_embeddings_concat\n",
    "\n",
    "\n",
    "def get_emb_media():\n",
    "    #média dos vetores e retirando outliers\n",
    "    embeddings = get_clean_embeddings()\n",
    "    sentiments = get_sentiments()\n",
    "    assemble_embeddings_media = np.zeros_like(embeddings[0])\n",
    "    vec = []\n",
    "    dist = []\n",
    "    for c in range(75):\n",
    "        tmp = np.array([])\n",
    "        vec = []\n",
    "        for i in embeddings:\n",
    "            vec += [i[c]]\n",
    "\n",
    "        centroid = np.zeros_like(vec[0])\n",
    "        for i in vec:\n",
    "            centroid = centroid + i\n",
    "        centroid = centroid/len(vec)\n",
    "\n",
    "        dist = []\n",
    "        for i in vec:\n",
    "            dist += [np.linalg.norm(i-centroid)]\n",
    "\n",
    "        limitante_distancia_para_corte = np.max(dist)\n",
    "\n",
    "        counter = 0\n",
    "        for n,i in enumerate(embeddings):\n",
    "            if dist[n]!=limitante_distancia_para_corte:\n",
    "                assemble_embeddings_media[c] += i[c] \n",
    "                counter+=1\n",
    "\n",
    "        assemble_embeddings_media[c] = assemble_embeddings_media[c]/counter\n",
    "    return assemble_embeddings_media\n",
    "\n",
    "\n",
    "def get_clean_embeddings():\n",
    "#Seleciona somente os vetores principais das nossas embeddings\n",
    "    sentiments = get_sentiments()\n",
    "    raw_embeddings = []\n",
    "    dimensions_size = []\n",
    "    for i in range(5):\n",
    "        tmp = get_vectors_embedding(i)\n",
    "        raw_embeddings += [tmp]\n",
    "        dimensions_size+=[len(get_sentiment_vector(tmp,sentiments[0]))]\n",
    "#Faz o corte para o menor tamanho de dimensão\n",
    "    n_dimensions = np.min(dimensions_size)\n",
    "    # n_dimensions = 10\n",
    "    mds = MDS(n_components=n_dimensions)\n",
    "#Trata embeddings, filtrando somente os sentimentos principais e colocando no numero minimo de dimensoes\n",
    "    embeddings = []\n",
    "    for i in range(5):\n",
    "        tmp_embedding = []\n",
    "        for s in sentiments:\n",
    "            tmp_embedding += [get_sentiment_vector(raw_embeddings[i],s)]\n",
    "        transformed_embedding = mds.fit_transform(tmp_embedding)\n",
    "        embeddings += [transformed_embedding]\n",
    "    # Calcula erro entre nossos modelos\n",
    "    for a in range(len(embeddings)):\n",
    "        for b in range(len(embeddings)):\n",
    "            embeddings[a],embeddings[b],r = procrustes(embeddings[a],embeddings[b])\n",
    "    return embeddings\n",
    "\n",
    "def print_anotado(emb):\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    ax.scatter(emb[:,0], emb[:,1])\n",
    "    n = get_sentiments()\n",
    "    \n",
    "    for i, txt in enumerate(n):\n",
    "        ax.annotate(\" \"+txt, (emb[:,0][i], emb[:,1][i]))\n",
    "\n",
    "def print_anotado2(emb):\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    for e in emb:\n",
    "        ax.scatter(e[:,0], e[:,1])\n",
    "        n = get_sentiments()\n",
    "\n",
    "        for i, txt in enumerate(n):\n",
    "            ax.annotate(txt, (e[:,0][i], e[:,1][i]))\n",
    "\n",
    "def print_2d(embs):\n",
    "    res = []\n",
    "    mds_2 = MDS(n_components=2)\n",
    "    for e in embs:\n",
    "        res += [mds_2.fit_transform(e)]\n",
    "    for p in res:\n",
    "        plt.scatter(p[:,0],p[:,1])\n",
    "\n",
    "def get_sentiment_vector(embedding, sentiment):\n",
    "    return embedding[sentiment][\"vectors\"][sentiment]\n",
    "\n",
    "def get_vectors_embedding(n):\n",
    "    files = os.listdir(\"models\")\n",
    "    model_file_name = []\n",
    "    for file in files:\n",
    "        model_file_name += [file]\n",
    "    escolhidos = [model_file_name[11],model_file_name[14],model_file_name[5],model_file_name[7],model_file_name[3]]\n",
    "    with open(\"models/\"+escolhidos[n], 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b\n",
    "\n",
    "def get_sentiments():\n",
    "    sentiments = np.load(\"./sentiments_list.npy\")\n",
    "    return sentiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
