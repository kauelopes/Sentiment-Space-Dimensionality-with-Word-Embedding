{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[0]\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "import json #https://stackoverflow.com/questions/7100125/storing-python-dictionaries\n",
    "import pickle #https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "import os\n",
    "#[1]\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.spatial import procrustes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#[2]\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from sklearn import decomposition\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE = get_emotion_embedding()\n",
    "sentiments = get_sentiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical values for p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0 0.0 0.0\n",
      "1 0.007206784168071933 8.531319132103985e-06 0.003529259643742473 0.004077889816912012\n",
      "2 0.010493993904163383 7.722654050352972e-06 0.0067742938131513655 0.007269970455829811\n",
      "3 0.013032305569693717 8.324390667053905e-06 0.008912540869600954 0.009493568438700637\n",
      "4 0.014916879664691983 6.793726174592676e-06 0.010940736564225645 0.011772404060213366\n",
      "5 0.016616188568739976 8.433606275331054e-06 0.012070101605253892 0.012878501086318585\n",
      "6 0.018120205915287603 8.328395844804186e-06 0.013720434953544825 0.014602217179944093\n",
      "7 0.01954915468254717 8.057605260205343e-06 0.014791760988873621 0.015916044178740884\n",
      "8 0.02067420131691701 7.844525315754382e-06 0.016293057187647262 0.017278844908838034\n",
      "9 0.021855610382772304 7.669350593833649e-06 0.017938877379422808 0.018454158773923243\n",
      "10 0.023134322437827384 7.363138188898518e-06 0.01875365460337248 0.01964638198659176\n",
      "11 0.023803260421549746 7.432504672943391e-06 0.019429369874140748 0.02046548379122279\n",
      "12 0.02505570654819777 7.69593825440656e-06 0.020363440248114786 0.021370006792967213\n",
      "13 0.025420404984110377 6.441141712979972e-06 0.021120126927113014 0.022160080178612387\n",
      "14 0.026773939762869327 6.682862413901703e-06 0.022722768542707363 0.023290460397890816\n"
     ]
    }
   ],
   "source": [
    "for k in range(15):\n",
    "    real = EE.copy()\n",
    "    distances_real = distance_matrix(real,real)\n",
    "    iterations = 300\n",
    "    trocas = k\n",
    "    erros = []\n",
    "    for i in range(iterations):\n",
    "        mod = real.copy()\n",
    "        for j in range(trocas):\n",
    "            a,b = np.random.randint(len(sentiments),size=2)\n",
    "            while(a==b):\n",
    "                a,b = np.random.randint(len(sentiments),size=2)\n",
    "            mod[a] = real[b]\n",
    "            mod[b] = real[a]\n",
    "\n",
    "        distance_mod = distance_matrix(mod,mod)\n",
    "        erro = calcula_stress(distances_real,distance_mod)\n",
    "        erros += [erro]\n",
    "    print(k, np.mean(erros),np.var(erros),sorted(erros)[15],sorted(erros)[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress values for each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 83.84558729344081 0.13695836999799835\n",
      "2 36.407061682481086 0.09023412080286992\n",
      "3 20.690486457554655 0.06801252115058443\n",
      "4 13.306478977054674 0.05453060242483441\n",
      "5 9.957608270940174 0.047161616534743156\n",
      "6 7.520384508599208 0.040975070611373184\n",
      "7 6.165443858914251 0.03709167843166618\n",
      "8 5.2125747391867785 0.03409711178561332\n",
      "9 4.4871891955574 0.03162822073119787\n",
      "10 3.8210499710157526 0.029177674652144023\n",
      "11 3.3730273859289053 0.027406088169874082\n",
      "12 3.0760863698653615 0.02616494889809195\n",
      "13 2.8635127414983517 0.025239980511612282\n",
      "14 2.528552949054131 0.023709584771149414\n",
      "15 2.3690003447117602 0.02294413423523367\n",
      "16 2.216295205642981 0.022187228271389303\n",
      "17 2.019613124045688 0.021172239810941768\n",
      "18 1.8992126390774864 0.02052671431376964\n",
      "19 1.7343976486463668 0.019610176583303045\n"
     ]
    }
   ],
   "source": [
    "stress = []\n",
    "x = []\n",
    "for i in range(1,20):\n",
    "    x+=[i]\n",
    "    r =MDS(n_components=i,max_iter=3000,n_init=10).fit(EE)\n",
    "    stress += [r.stress_]\n",
    "    print(i,r.stress_,calcula_stress_embeddings(EE,r.embedding_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define quantidade stress-per-point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('astonished', -0.0002811271358145184)\n",
      "('determined', 0.0006021000821617717)\n",
      "('serene', 0.00013996985755006242)\n",
      "('joyous', 0.0003365630752256987)\n",
      "('desperate', 1.3458985313671845e-05)\n",
      "('melancholic', 7.926144332501273e-05)\n",
      "('amorous', 5.1061197400115166e-05)\n",
      "('condescending', -0.0007848213515741359)\n",
      "('distrustful', -7.543416364615141e-05)\n",
      "('passionate', -0.0006331066308214311)\n",
      "('dissatisfied', 0.0006040583542706313)\n",
      "('empathic', -6.488590449835185e-05)\n",
      "('lusting', 0.0005480167025402605)\n",
      "('happy', -0.0003388567965483813)\n",
      "('miserable', -0.00034444318402454543)\n",
      "('indignant', 0.000362223875584905)\n",
      "('jealous', 0.00027840556902411495)\n",
      "('amused', -0.00030961339176370506)\n",
      "('disgusted', -0.0003213735109613147)\n",
      "('hopeful', -0.0005259340727305911)\n",
      "('discontented', 0.00021058062486295492)\n",
      "('sad', 0.0007664841014329571)\n",
      "('insulted', 0.0006757980513041051)\n",
      "('distressed', 0.00011503796922657239)\n",
      "('tired', -0.0001305377834422694)\n",
      "('suspicious', 9.898912573755303e-05)\n",
      "('contemptuous', 0.0006392186243697334)\n",
      "('polite', -0.000280741903345344)\n",
      "('friendly', -0.00015488335521866847)\n",
      "('surprise', -0.0003552335169815929)\n",
      "('confused', 4.888008553310952e-05)\n",
      "('peaceful', 0.00013952803673816794)\n",
      "('hesitant', -0.0001407829275656275)\n",
      "('interested', 0.0005750733929221208)\n",
      "('convinced', -0.0008214913547166386)\n",
      "('contemplative', -0.00017438434758371146)\n",
      "('envious', -5.545374376697554e-05)\n",
      "('courageous', 0.0005032594760437242)\n",
      "('expectant', -8.73818565211848e-05)\n",
      "('fear', 7.104824682838129e-05)\n",
      "('impatient', 7.392388848004305e-07)\n",
      "('delighted', -0.0002726157166061255)\n",
      "('annoyed', 0.0005199938033915025)\n",
      "('disappointed', -0.0008066960401230672)\n",
      "('conceited', 0.0003675509251430814)\n",
      "('apathetic', 1.7966359732460302e-05)\n",
      "('satisfied', 0.0008337654291864227)\n",
      "('longing', 9.269967245995048e-05)\n",
      "('attentive', -0.0006872945183649115)\n",
      "('content', -2.546563257894985e-05)\n",
      "('dejected', 0.00011053660646666297)\n",
      "('bitter', 0.00020236236612297676)\n",
      "('guilt', 0.000892874424443621)\n",
      "('serious', 0.00018036150922697003)\n",
      "('confident', -0.0008852263960043849)\n",
      "('triumphant', 0.00043234448727982877)\n",
      "('worried', 0.0008542152881414466)\n",
      "('relaxed', -0.00025194990685327434)\n",
      "('startled', -0.00047244949945442205)\n",
      "('bored', 0.0001555855543282081)\n",
      "('frustrated', 0.00018864744201056716)\n",
      "('depressed', 0.0003804757655897356)\n",
      "('calm', 0.0006849960157759988)\n",
      "('alarmed', -6.775433778132e-05)\n",
      "('tense', -0.00048908407392248)\n",
      "('angry', 2.013631949600303e-05)\n",
      "('embarrassed', 0.0003829139366819667)\n",
      "('gloomy', -0.00043799351336996917)\n",
      "('despondent', -0.0005180316036260679)\n",
      "('impressed', -0.0004737128108626282)\n",
      "('enthusiastic', 9.123584708041477e-05)\n",
      "('wavering', 0.0004916235432469857)\n",
      "('ambitious', 0.0004793345033042018)\n",
      "('excited', -0.00031691539651379497)\n"
     ]
    }
   ],
   "source": [
    "ssp = []\n",
    "t = []\n",
    "for i in range(len(sentiments)):\n",
    "    a = (sentiments[i],get_stresses_per_point(i,EE,2))\n",
    "    t += [a[1]]\n",
    "    print(a)\n",
    "    ssp += [a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guilt', 0.000892874424443621),\n",
       " ('worried', 0.0008542152881414466),\n",
       " ('satisfied', 0.0008337654291864227),\n",
       " ('sad', 0.0007664841014329571),\n",
       " ('calm', 0.0006849960157759988),\n",
       " ('insulted', 0.0006757980513041051),\n",
       " ('contemptuous', 0.0006392186243697334),\n",
       " ('dissatisfied', 0.0006040583542706313),\n",
       " ('determined', 0.0006021000821617717),\n",
       " ('interested', 0.0005750733929221208),\n",
       " ('lusting', 0.0005480167025402605),\n",
       " ('annoyed', 0.0005199938033915025),\n",
       " ('courageous', 0.0005032594760437242),\n",
       " ('wavering', 0.0004916235432469857),\n",
       " ('ambitious', 0.0004793345033042018),\n",
       " ('triumphant', 0.00043234448727982877),\n",
       " ('embarrassed', 0.0003829139366819667),\n",
       " ('depressed', 0.0003804757655897356),\n",
       " ('conceited', 0.0003675509251430814),\n",
       " ('indignant', 0.000362223875584905),\n",
       " ('joyous', 0.0003365630752256987),\n",
       " ('jealous', 0.00027840556902411495),\n",
       " ('discontented', 0.00021058062486295492),\n",
       " ('bitter', 0.00020236236612297676),\n",
       " ('frustrated', 0.00018864744201056716),\n",
       " ('serious', 0.00018036150922697003),\n",
       " ('bored', 0.0001555855543282081),\n",
       " ('serene', 0.00013996985755006242),\n",
       " ('peaceful', 0.00013952803673816794),\n",
       " ('distressed', 0.00011503796922657239),\n",
       " ('dejected', 0.00011053660646666297),\n",
       " ('suspicious', 9.898912573755303e-05),\n",
       " ('longing', 9.269967245995048e-05),\n",
       " ('enthusiastic', 9.123584708041477e-05),\n",
       " ('melancholic', 7.926144332501273e-05),\n",
       " ('fear', 7.104824682838129e-05),\n",
       " ('amorous', 5.1061197400115166e-05),\n",
       " ('confused', 4.888008553310952e-05),\n",
       " ('angry', 2.013631949600303e-05),\n",
       " ('apathetic', 1.7966359732460302e-05),\n",
       " ('desperate', 1.3458985313671845e-05),\n",
       " ('impatient', 7.392388848004305e-07),\n",
       " ('content', -2.546563257894985e-05),\n",
       " ('envious', -5.545374376697554e-05),\n",
       " ('empathic', -6.488590449835185e-05),\n",
       " ('alarmed', -6.775433778132e-05),\n",
       " ('distrustful', -7.543416364615141e-05),\n",
       " ('expectant', -8.73818565211848e-05),\n",
       " ('tired', -0.0001305377834422694),\n",
       " ('hesitant', -0.0001407829275656275),\n",
       " ('friendly', -0.00015488335521866847),\n",
       " ('contemplative', -0.00017438434758371146),\n",
       " ('relaxed', -0.00025194990685327434),\n",
       " ('delighted', -0.0002726157166061255),\n",
       " ('polite', -0.000280741903345344),\n",
       " ('astonished', -0.0002811271358145184),\n",
       " ('amused', -0.00030961339176370506),\n",
       " ('excited', -0.00031691539651379497),\n",
       " ('disgusted', -0.0003213735109613147),\n",
       " ('happy', -0.0003388567965483813),\n",
       " ('miserable', -0.00034444318402454543),\n",
       " ('surprise', -0.0003552335169815929),\n",
       " ('gloomy', -0.00043799351336996917),\n",
       " ('startled', -0.00047244949945442205),\n",
       " ('impressed', -0.0004737128108626282),\n",
       " ('tense', -0.00048908407392248),\n",
       " ('despondent', -0.0005180316036260679),\n",
       " ('hopeful', -0.0005259340727305911),\n",
       " ('passionate', -0.0006331066308214311),\n",
       " ('attentive', -0.0006872945183649115),\n",
       " ('condescending', -0.0007848213515741359),\n",
       " ('disappointed', -0.0008066960401230672),\n",
       " ('convinced', -0.0008214913547166386),\n",
       " ('confident', -0.0008852263960043849)]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ssp,key=lambda a: a[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_list = [10,5,24,39,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_EE = []\n",
    "for a in range(len(EE)):\n",
    "    if a not in outliers_list:\n",
    "        clean_EE += [EE[a]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stresses_per_point(p, emb,d):\n",
    "    stress_original = []\n",
    "    stress_one_out = []\n",
    "\n",
    "    for i in range(5):\n",
    "        r =MDS(n_components=d,max_iter=3000,n_init=10).fit(emb)\n",
    "        stress_original += [calcula_stress_embeddings(emb,r.embedding_)]\n",
    "#         stress_original += [r.stress_]\n",
    "\n",
    "\n",
    "    emb_one_out = emb[:p]+emb[p+1:]\n",
    "    for i in range(5):\n",
    "        r =MDS(n_components=d,max_iter=3000,n_init=10).fit(emb_one_out)\n",
    "        stress_one_out += [calcula_stress_embeddings(emb_one_out,r.embedding_)]\n",
    "#         stress_one_out += [r.stress_]\n",
    "    return np.mean(stress_original)-np.mean(stress_one_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_embedding():\n",
    "    return get_emb_concat()\n",
    "\n",
    "def get_final_embs(dimensions = 200):\n",
    "    embs = get_clean_embeddings()\n",
    "    embs += [get_emb_soma()]\n",
    "    embs += [get_emb_concat()]\n",
    "\n",
    "\n",
    "    mds = MDS(n_components=dimensions)\n",
    "    #Trata embeddings, filtrando somente os sentimentos principais e colocando no numero minimo de dimensoes\n",
    "    embeddings = []\n",
    "    for i in range(len(embs)):\n",
    "        transformed_embedding = mds.fit_transform(embs[i])\n",
    "        embeddings += [transformed_embedding]\n",
    "    embs = embeddings\n",
    "\n",
    "    for a in range(len(embs)):\n",
    "        for b in range(len(embs)):\n",
    "            embs[a],embs[b],r = procrustes(embs[a],embs[b])\n",
    "    for i in range(200):\n",
    "        a = np.random.randint(len(embs))\n",
    "        b = np.random.randint(len(embs))\n",
    "        embs[a],embs[b],r = procrustes(embs[a],embs[b])\n",
    "    return embs\n",
    "\n",
    "def calcula_stress_embeddings(d_original, d_proposta):\n",
    "    d_original = distance_matrix(d_original,d_original)\n",
    "    d_proposta = distance_matrix(d_proposta,d_proposta)\n",
    "    a = np.sum((d_original-d_proposta)**2)\n",
    "    b = np.sum(d_original**2)\n",
    "    return np.sqrt(a/b)/4\n",
    "\n",
    "def calcula_stress(d_original, d_proposta):\n",
    "    a = np.sum((d_original-d_proposta)**2)\n",
    "    b = np.sum(d_original**2)\n",
    "    return np.sqrt(a/b)/4\n",
    "\n",
    "def get_emb_soma():\n",
    "    embeddings = get_clean_embeddings()\n",
    "    sentiments = get_sentiments()\n",
    "    assemble_embeddings_soma = np.zeros_like(embeddings[0])\n",
    "    for i in embeddings:\n",
    "        for c in range(len(sentiments)):\n",
    "            assemble_embeddings_soma[c] = assemble_embeddings_soma[c] + i[c]\n",
    "    return assemble_embeddings_soma\n",
    "\n",
    "def get_emb_concat():\n",
    "    embeddings = get_clean_embeddings()\n",
    "    sentiments = get_sentiments()\n",
    "    assemble_embeddings_concat = []\n",
    "\n",
    "    for c in range(len(sentiments)):\n",
    "        tmp = np.array([])\n",
    "        for i in embeddings:\n",
    "            tmp = np.concatenate((tmp,i[c]))\n",
    "        assemble_embeddings_concat += [tmp]\n",
    "    return assemble_embeddings_concat\n",
    "\n",
    "\n",
    "def get_emb_media():\n",
    "    #média dos vetores e retirando outliers\n",
    "    embeddings = get_clean_embeddings()\n",
    "    sentiments = get_sentiments()\n",
    "    assemble_embeddings_media = np.zeros_like(embeddings[0])\n",
    "    vec = []\n",
    "    dist = []\n",
    "    for c in range(len(sentiments)):\n",
    "        tmp = np.array([])\n",
    "        vec = []\n",
    "        for i in embeddings:\n",
    "            vec += [i[c]]\n",
    "\n",
    "        centroid = np.zeros_like(vec[0])\n",
    "        for i in vec:\n",
    "            centroid = centroid + i\n",
    "        centroid = centroid/len(vec)\n",
    "\n",
    "        dist = []\n",
    "        for i in vec:\n",
    "            dist += [np.linalg.norm(i-centroid)]\n",
    "\n",
    "        limitante_distancia_para_corte = np.max(dist)\n",
    "\n",
    "        counter = 0\n",
    "        for n,i in enumerate(embeddings):\n",
    "            if dist[n]!=limitante_distancia_para_corte:\n",
    "                assemble_embeddings_media[c] += i[c] \n",
    "                counter+=1\n",
    "\n",
    "        assemble_embeddings_media[c] = assemble_embeddings_media[c]/counter\n",
    "    return assemble_embeddings_media\n",
    "\n",
    "\n",
    "def get_clean_embeddings():\n",
    "#Seleciona somente os vetores principais das nossas embeddings\n",
    "    sentiments = get_sentiments()\n",
    "    raw_embeddings = []\n",
    "    dimensions_size = []\n",
    "    for i in range(4):\n",
    "        tmp = get_vectors_embedding(i)\n",
    "        raw_embeddings += [tmp]\n",
    "        dimensions_size+=[len(get_sentiment_vector(tmp,sentiments[0]))]\n",
    "#Faz o corte para o menor tamanho de dimensão\n",
    "    n_dimensions = np.min(dimensions_size)\n",
    "    # n_dimensions = 10\n",
    "    mds = MDS(n_components=n_dimensions)\n",
    "#Trata embeddings, filtrando somente os sentimentos principais e colocando no numero minimo de dimensoes\n",
    "    embeddings = []\n",
    "    for i in range(4):\n",
    "        tmp_embedding = []\n",
    "        for s in sentiments:\n",
    "            tmp_embedding += [get_sentiment_vector(raw_embeddings[i],s)]\n",
    "        transformed_embedding = mds.fit_transform(tmp_embedding)\n",
    "        embeddings += [transformed_embedding]\n",
    "    # Calcula erro entre nossos modelos\n",
    "    for a in range(len(embeddings)):\n",
    "        for b in range(len(embeddings)):\n",
    "            embeddings[a],embeddings[b],r = procrustes(embeddings[a],embeddings[b])\n",
    "    return embeddings\n",
    "\n",
    "def print_anotado(emb):\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    ax.scatter(emb[:,0], emb[:,1])\n",
    "    n = get_sentiments()\n",
    "    \n",
    "    for i, txt in enumerate(n):\n",
    "        ax.annotate(\" \"+txt, (emb[:,0][i], emb[:,1][i]))\n",
    "\n",
    "def print_anotado2(emb):\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    for e in emb:\n",
    "        ax.scatter(e[:,0], e[:,1])\n",
    "        n = get_sentiments()\n",
    "\n",
    "        for i, txt in enumerate(n):\n",
    "            ax.annotate(txt, (e[:,0][i], e[:,1][i]))\n",
    "\n",
    "def print_2d(embs):\n",
    "    res = []\n",
    "    mds_2 = MDS(n_components=2)\n",
    "    for e in embs:\n",
    "        res += [mds_2.fit_transform(e)]\n",
    "    for p in res:\n",
    "        plt.scatter(p[:,0],p[:,1])\n",
    "\n",
    "def get_sentiment_vector(embedding, sentiment):\n",
    "    return embedding[sentiment][\"vectors\"][sentiment]\n",
    "\n",
    "def get_vectors_embedding(n):\n",
    "    files = os.listdir(\"models\")\n",
    "    model_file_name = []\n",
    "    for file in files:\n",
    "        model_file_name += [file]\n",
    "    escolhidos = [model_file_name[14],model_file_name[5],model_file_name[7],model_file_name[3]]\n",
    "    with open(\"models/\"+escolhidos[n], 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b\n",
    "\n",
    "def get_sentiments_old():\n",
    "    sentiments = np.load(\"./sentiments_list.npy\")\n",
    "    return sentiments\n",
    "def get_sentiments():\n",
    "    sentiments = np.load(\"./sentiments_list.npy\")\n",
    "    sentiments = np.concatenate((sentiments[:26],sentiments[27:]))\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
